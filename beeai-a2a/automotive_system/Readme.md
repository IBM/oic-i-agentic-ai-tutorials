# ğŸš— Predictive Maintenance Automation

Using BeeAI + Ollama + Watsonx Orchestrate + Scheduler

This repository contains a complete **end-to-end predictive maintenance automation system** powered by:

* **BeeAI Framework (A2A agent with tool-calling)**
* **Ollama Granite 3.3 8B (local LLM runtime)**
* **Watsonx Orchestrate (flows, tools, agents)**
* **WXO Scheduler (recurring automation)**

The system can run:

### âœ” **Locally**

(For development, demos, offline usage, edge devices)

### âœ” **Inside Watsonx Orchestrate (SaaS)**

(For enterprise-grade scheduling, user interface, governance)

---

## Folder Structure

```
automotive_system/
 â”œâ”€â”€ beeai_agent/              # BeeAI Predictive Maintenance A2A server
 â”‚    â”œâ”€â”€ __main__.py
 â”‚    â”œâ”€â”€ tools_dummy.py
 â”‚    â”œâ”€â”€ Dockerfile
 â”‚    â””â”€â”€ pyproject.toml
 â”‚
 â”œâ”€â”€ beeai_host/               # Simple BeeAI A2A client (local test tool)
 â”‚    â”œâ”€â”€ __main__.py
 â”‚    â”œâ”€â”€ Dockerfile
 â”‚    â””â”€â”€ pyproject.toml
 â”‚
 â”œâ”€â”€ wxo_tools/                # WXO Tools (Python)
 â”‚    â”œâ”€â”€ predict_failure.py
 â”‚    â”œâ”€â”€ order_parts_tool.py
 â”‚    â”œâ”€â”€ book_slot_tool.py
 â”‚    â”œâ”€â”€ maintenance_cost_tool.py
 â”‚    â””â”€â”€ send_notification_tool.py
 â”‚
 â”œâ”€â”€ wxo_flows/
 â”‚    â””â”€â”€ predictive_maintenance_flow.py
 â”‚
 â”œâ”€â”€ wxo_agents/
 â”‚    â”œâ”€â”€ maintenance_agent.yaml
 â”‚    â””â”€â”€ maintenance_scheduler_agent.yaml
 â”‚
 â”œâ”€â”€ scripts/
 â”‚    â””â”€â”€ import_all.sh        # Import tools + flows + agents to WXO
 â”‚
 â”œâ”€â”€ docker-compose.yml
 â”œâ”€â”€ maintenance_flow.py
 â”œâ”€â”€ maintenance_scheduler_agent.yaml
 â””â”€â”€ README_GITHUB.md
```

---

## **Requirements**

### Local Requirements

* macOS / Linux / Windows WSL2
* Python 3.11+
* Ollama installed locally
* Granite model pulled:

```bash
ollama pull granite4:350m
```

* BeeAI Framework:

```bash
pip install beeai-framework 'beeai-framework[a2a]'
```

### Watsonx Orchestrate Requirements

* Watsonx Orchestrate ADK installed:

```bash
pip install ibm-watsonx-orchestrate
```

* Access to Orchestrate workspace
* API key configured (`orchestrate login`)

---

## **Part 1 â€” Run Locally (BeeAI + Ollama)**

This mode is ideal for development, debugging, and demonstrating the predictive maintenance LLM agent offline.

---

### **1. Start Ollama**

```bash
ollama serve &
```

Test model:

```bash
ollama run granite4:350m "hello"
```

---

### **2. Start the BeeAI A2A Server**

From project root:

```bash
cd automotive_system
python -m beeai_agent
```

If successful, you will see:

```
A2A server running on port 9999
Tools loaded: [...]
```

---

### **3. Test Using the BeeAI A2A Host**

Open another terminal:

```bash
cd automotive_system/beeai_host
python __main__.py TRUCK-22
```

You should see a full maintenance summary:

âœ“ vehicle location
âœ“ driver schedule
âœ“ dealership slots
âœ“ parts inventory
âœ“ recommended repair time

---

## **Part 2 â€” Run in Watsonx Orchestrate (WXO)**

Watsonx Orchestrate provides:

* UI for interacting with your agent
* A flow engine for automation
* A scheduler for recurring tasks
* Governance & execution history

---

### **1. Import All Tools, Flows, and Agents**

Run the script:

```bash
cd automotive_system/scripts
./import_all.sh
```

This imports:

âœ” Python tools (predict failure, cost, booking, parts, notifications)
âœ” A predictive maintenance flow
âœ” On-demand and scheduled agents

---

### **2. Interact With Agent in WXO UI**

Open Watsonx Orchestrate â†’ Chat interface.

Try:

```
Run a maintenance check for TRUCK-22
```

You will receive a complete maintenance report generated by BeeAI and orchestrated by WXO.

---

### **3. Schedule Automatic Maintenance Checks**

You can ask:

```
Schedule a maintenance check for TRUCK-22 every day at 9am.
```

WXO will:

* Create a scheduled job
* Run your workflow at the specified time
* Track run history
* Notify you when maintenance is due

To list schedules:

```
List my schedules
```

To delete one:

```
Delete schedule <id>
```

(Uses Orchestrate intrinsic scheduling tools.)

---

## **How the Full System Works**

### 1. BeeAI generates predictions

The A2A server calls multiple automotive tools:

* get_vehicle_location
* get_driver_schedule
* get_dealership_slots
* get_parts_inventory

### 2. Watsonx Orchestrate runs the workflow

* Predict failure
* Check inventory
* Book slot
* Compute cost
* Notify fleet manager

### 3. Scheduler triggers the workflow automatically

Daily, weekly, or custom frequency.

### 4. Everything appears in the WXO UI

* Results
* History
* Logs
* Errors
* Schedules

---

## **Troubleshooting**

### âœ” Agent says â€œvehicle not foundâ€

Your BeeAI server did not load tools.
Ensure:

```python
@tool(description="...")
```

is present in each tool decorator.

### âœ” A2A server error: no module named tools_dummy

Run BeeAI from project root:

```
python -m beeai_agent
```

### âœ” WXO cannot find your flow

Check import directory:

```
wxo_flows/predictive_maintenance_flow.py
```

### âœ” Scheduler not working

Confirm you used `maintenance_scheduler_agent.yaml`
and imported intrinsic tools:

```
i__get_schedule_intrinsic_tool__
i__delete_schedule_intrinsic_tool__
i__get_flow_status_intrinsic_tool__
```

---

## **Conclusion**

You now have a fully operational:
#### âœ” Predictive Maintenance LLM Agent (BeeAI + Granite)
#### âœ” End-to-End Workflow Automation (WXO Flow Builder)
#### âœ” Enterprise Orchestration and Scheduling (WXO Scheduler)
#### âœ” Local + Cloud Hybrid Setup

This project demonstrates how local LLM agents can integrate seamlessly with enterprise orchestration platforms.

